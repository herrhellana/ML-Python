{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Майнор Интеллектуальный анализ данных / Введение в анализ данных\n",
    "\n",
    "## Домашнее задание 3. Логистическая регрессия и случайный лес.\n",
    "\n",
    "В этом задании вам предстоит:\n",
    "- поработать с логистической регрессией (полная реализация не потребуется, однако можно заработать бонусные баллы)\n",
    "- воспроизвести подход случайного леса через одно решающее дерево, поэкспериментировать со случайным лесом.\n",
    "\n",
    "На все вопросы требуется отвечать развёрнуто, аппелируя к полученным значениям или графикам, ответы вписывать в отдельную ячейку, выбрав для неё тип \"Markdown\". От полноты и качества ответов будет во многом зависеть ваша итоговая оценка.\n",
    "\n",
    "Задание выполняется самостоятельно, плагиат будет стандартно наказываться лишением всех баллов за задание.\n",
    "- Максимальная оценка за задание: 10 баллов.\n",
    "- Дата выдачи: 28.04.2018\n",
    "- Срок сдачи: 23:59 18.05.2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 0. Подготовка данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для наших экспериентов возьмём обучающую выборку [отсюда](https://www.kaggle.com/iabhishekofficial/mobile-price-classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('mobile_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решается задача многоклассовой классификации — определение ценовой категории телефона. Для простоты перейдём к задаче бинарной классификации — пусть исходные классы 0 и 1 соответствуют классу 0 новой целевой переменной, а остальные классу 1.\n",
    "\n",
    "Замените целевую переменную, отделите её в отдельную переменную и удалите из исходной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "# 0 if price_range <= 1, else 1\n",
    "\n",
    "price_range = [0 if x <= 1 else 1 for x in train.iloc[:, -1]]\n",
    "train.drop('price_range', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите выборку на обучающую и тестовую части в соотношении 7 к 3. Для этого можно использовать `train_test_split` из scikit-learn. Не забудьте зафиксировать сид для разбиения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "random.seed(1234)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, price_range, train_size = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Логистическая регрессия.\n",
    "\n",
    "[4 балла]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части вы будете обучать самый простой бинарный классификатор — логистическую регрессию. Будем использовать готовую реализацию `LogisticRegression` из scikit-learn.\n",
    "\n",
    "Логистическая регрессия — линейный метод, то есть в нём предсказание алгоритма вычислаяется как скалярное произведение признаков и весов алгоритма: \n",
    "\n",
    "$$\n",
    "b(x) = w_0 + \\langle w, x \\rangle = w_0 + \\sum_{i=1}^{d} w_i x_i\n",
    "$$\n",
    "\n",
    "Для вычисления вероятности положительного класса применяется сигмода. В результате предсказание вероятности принадлежности объекта к положительному классу можно записать как: \n",
    "\n",
    "$$\n",
    "P(y = +1 | x) = \\frac{1}{1 + \\exp(- w_0 - \\langle w, x \\rangle )}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забывайте, что для линейных методов матрицу объекты-признаки необходимо предварительно нормировать (то есть привести каждый признак к одному и тому же масштабу одним из способов). Для этого можно воспользоваться `StandardScaler` или сделать это вручную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression()\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X_train, X_test = preprocessing.scale(X_train), preprocessing.scale(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите логистическую регрессию. Сделайте предсказания для тестовой части, посчитайте по ним ROC-AUC и Accuracy (порог 0.5). Хорошо ли удаётся предсказывать целевую переменную?\n",
    "\n",
    "Не забывайте, что метод `predict_proba` вычисляет вероятности обоих классов выборки, а в бинарной классификации нас интересует в первую очередь вероятность принадлежности к положительному классу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "\n",
    "logisticRegr.fit(X_train, y_train) # fitting the model\n",
    "y_pred = logisticRegr.predict(X_test) # predict\n",
    "\n",
    "y_pred_1 = logisticRegr.predict_proba(X_test) # predict proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97542788509658696"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROC-AUC\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97499999999999998"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, accuracy и ROC-AUC очень высокие -- алгоритм прекрасно предсказывает, т.е. доля правильных ответов большая (accuracy), качество классификатора превосходное (roc-auc). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У обученной логистической регрессии есть два аттрибута: `coef_` и `intercept_`, которые соответствуют весам $w$ и $w_0$. Это и есть результат обучения логистической регрессии. Попробуйте с помощью них (с помощью всё той же обученной ранее логистической регрессии) посчитать \"сырое\" предсказание алгоритма $b(x)$. \n",
    "\n",
    "Постройте гистограмму полученных значений и ответьте на вопросы:\n",
    "- Какие значения принимает такое предсказание?\n",
    "- Похожи ли эти значения на вероятность классов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "y_pred_raw = logisticRegr.intercept_ + np.dot(logisticRegr.coef_, X_test.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -7.35024928e+00,  -1.48492151e+01,  -5.57666011e-01,\n",
       "          6.68516278e+00,   1.92750174e+01,   6.80484918e+00,\n",
       "         -5.03128741e+00,  -2.93062097e+00,   8.90108818e+00,\n",
       "          2.48590631e+00,  -4.50297513e-01,  -9.21015692e+00,\n",
       "         -1.15241028e+01,   9.65183053e+00,   7.53177731e+00,\n",
       "          4.78324873e+00,   1.53071531e+01,  -1.74307040e+01,\n",
       "          1.42162492e+01,  -1.01970824e+01,  -7.58709313e+00,\n",
       "         -6.99017950e+00,  -4.10971653e-01,   4.38071670e+00,\n",
       "         -3.55679014e+00,  -1.10918836e+01,  -9.60474619e+00,\n",
       "          1.52796641e+01,   4.02150299e+00,   2.39817805e+00,\n",
       "          2.39426366e+00,   6.63226639e-01,   4.79967905e+00,\n",
       "          1.88221813e+00,   1.53956770e+00,   1.53587611e+01,\n",
       "          1.60497357e+01,  -1.57493187e+01,  -8.60170279e+00,\n",
       "         -5.47945462e+00,   1.02591911e+01,   1.21258610e+00,\n",
       "         -8.64963542e-01,  -5.07078984e+00,   9.24075353e+00,\n",
       "          1.86108953e+00,  -2.31881100e+00,  -9.81001993e+00,\n",
       "          1.12347707e+01,  -1.38292868e+01,  -9.48030426e+00,\n",
       "          7.52369400e+00,   9.74629657e+00,   5.70522061e+00,\n",
       "          7.72871707e+00,   4.44010107e+00,  -1.10320269e+01,\n",
       "          2.56559478e+00,   9.89792067e+00,   1.04372928e+01,\n",
       "          1.52824124e+01,  -8.91272376e-01,  -5.76162271e+00,\n",
       "         -9.04029389e+00,   7.55021523e+00,  -1.30433189e+01,\n",
       "         -2.66517164e+00,   9.67189990e+00,   1.02051597e+01,\n",
       "          2.04619007e+00,  -7.58662707e+00,   2.21136992e+00,\n",
       "         -1.06283146e+01,   3.74571158e+00,   9.07912206e+00,\n",
       "         -8.68640047e+00,  -6.81804736e+00,  -1.64291952e+01,\n",
       "         -1.09915917e+01,  -6.41325170e-01,  -3.48385480e+00,\n",
       "         -1.67858605e+01,   1.72065617e+01,   4.87893048e+00,\n",
       "          5.84326287e+00,  -1.27534697e+01,   3.28219565e+00,\n",
       "          5.98177839e+00,   6.87549759e+00,  -9.69008351e+00,\n",
       "          1.67400006e+00,  -2.50645214e+00,  -9.50369107e+00,\n",
       "         -4.44337038e+00,  -7.35449451e+00,  -1.28669407e+01,\n",
       "          1.74534626e+01,  -2.73335112e+00,   3.94631815e+00,\n",
       "         -2.05997443e+01,   1.07448922e+01,  -8.24547172e+00,\n",
       "          1.41864384e+01,   1.28011440e+01,  -1.13869469e+01,\n",
       "          3.34272979e+00,   1.17324271e+01,   6.80500621e-01,\n",
       "          2.18289367e+00,   9.06960044e+00,  -1.72771813e+01,\n",
       "         -2.36460960e+00,  -1.47457947e+01,  -1.42371903e+01,\n",
       "          1.50084083e+01,  -8.64173817e+00,   7.89210418e+00,\n",
       "         -1.23451872e+01,   1.38982421e+01,  -1.46563309e+01,\n",
       "         -1.35326646e+01,   1.65279391e-01,   7.28364694e+00,\n",
       "          1.19508869e+01,  -6.82355688e+00,   1.48825917e+01,\n",
       "         -1.18926433e+01,  -4.44757469e+00,   2.56753588e+00,\n",
       "          7.86312752e+00,   4.62285782e+00,  -7.66970736e-01,\n",
       "         -6.54633696e+00,   5.20129897e+00,   3.54089409e+00,\n",
       "          1.87905859e+01,   1.26431151e+01,   8.91038707e+00,\n",
       "          1.15864531e+01,   5.56212313e+00,   5.58572738e+00,\n",
       "         -1.02291753e+01,   4.85360759e+00,  -1.52665187e-01,\n",
       "          1.24227388e+01,   6.91227384e+00,   7.75761439e+00,\n",
       "          1.22061796e+01,  -1.44975401e+01,   7.83361055e+00,\n",
       "          1.09169621e+00,   7.94678152e+00,   2.86867270e+00,\n",
       "          3.30981344e+00,  -8.85051190e+00,  -8.77640232e+00,\n",
       "          1.28566852e+01,  -8.03041578e+00,  -1.04418761e+01,\n",
       "          6.10097452e-01,  -1.01421236e+01,   1.47412707e+01,\n",
       "         -2.91681628e-01,   2.05101834e+00,  -4.30891293e+00,\n",
       "          6.57769019e+00,  -4.75495736e+00,  -1.28213687e+01,\n",
       "          3.45430410e+00,   4.98705278e+00,  -6.03237886e+00,\n",
       "         -6.78178942e+00,   8.80877674e+00,  -2.76510151e+00,\n",
       "          1.73907879e+00,   1.01051457e+01,  -1.24407893e+01,\n",
       "          5.71653600e+00,   1.57399444e+01,  -4.62835897e+00,\n",
       "         -3.04811150e+00,  -6.56722835e-01,  -5.74906517e+00,\n",
       "         -5.04912484e+00,   4.36100164e+00,   2.08362052e+00,\n",
       "          1.75767738e+01,   1.48395943e+00,  -6.37482652e+00,\n",
       "          7.17278826e+00,  -2.54647485e+00,  -2.39106985e-01,\n",
       "         -1.42596861e+01,   3.76639240e+00,   1.37704330e+01,\n",
       "          1.26438427e+01,   8.60678321e+00,  -2.26131358e+00,\n",
       "          1.29572836e+01,  -2.12265450e+00,   8.65470374e+00,\n",
       "          3.95987397e-01,   6.67152601e-01,   1.37698841e+01,\n",
       "         -1.35615338e+01,  -4.67512069e+00,   4.44424078e+00,\n",
       "          1.24676122e+01,  -6.46405021e+00,   8.70070238e+00,\n",
       "          7.37827429e+00,   1.35522654e+00,  -7.75741184e+00,\n",
       "         -1.03391028e+01,   1.01520261e-01,   7.02561595e-01,\n",
       "         -6.59853821e+00,   8.20957764e+00,   5.24792631e+00,\n",
       "         -1.12850622e+01,  -5.72821676e+00,   1.20080309e+01,\n",
       "         -1.16465238e+01,  -1.27597112e+01,   1.22839262e+01,\n",
       "         -9.34104464e+00,  -1.16506337e+01,  -8.00772843e+00,\n",
       "          8.48148036e+00,   4.50728356e+00,   1.83458359e+00,\n",
       "          9.80085940e+00,   1.29105895e+01,   4.67810347e+00,\n",
       "         -8.92315360e+00,   1.11081347e+01,   7.60004687e+00,\n",
       "          8.44761698e-01,   1.11128429e+01,   2.52298668e+00,\n",
       "          6.49652682e-01,   4.40172439e+00,   2.24663592e+00,\n",
       "          7.84999947e+00,   3.48189912e+00,  -5.74961475e+00,\n",
       "         -5.29793260e+00,  -5.42394068e+00,   8.30613347e+00,\n",
       "          6.55210088e+00,  -5.11284474e+00,   3.60535441e+00,\n",
       "         -6.94061220e+00,  -7.53542782e+00,   1.55125895e+00,\n",
       "         -2.96731078e+00,   1.06724453e+00,  -3.51805287e+00,\n",
       "          4.61891892e+00,   8.38974966e+00,  -1.20373798e+01,\n",
       "          6.56997751e+00,  -8.08672805e+00,  -7.80868025e+00,\n",
       "          5.21150238e+00,   1.67722653e+01,  -9.98756787e+00,\n",
       "         -5.70181526e+00,  -5.96640946e-02,   2.01063488e+01,\n",
       "         -7.94735475e+00,   5.28438124e+00,   7.90055090e+00,\n",
       "         -3.50547125e+00,  -1.43813643e+01,   5.62596287e+00,\n",
       "          1.31957842e-01,   1.92175709e+00,  -1.02043818e+01,\n",
       "          5.72299774e+00,   2.19857688e+00,  -1.35465466e+01,\n",
       "         -4.97532296e+00,   5.01120622e+00,  -2.57753796e+00,\n",
       "          8.57243042e+00,  -1.49900196e+01,   3.52074041e+00,\n",
       "         -1.33878386e+01,   1.43402414e+00,  -1.07187845e+01,\n",
       "          1.07389152e+00,   9.13472174e+00,  -7.48116240e+00,\n",
       "          2.26928277e+00,  -8.98850806e+00,   6.34291151e+00,\n",
       "          1.31715884e+01,  -5.87793429e+00,   1.58732539e+01,\n",
       "         -1.02555085e+01,   8.52712813e+00,  -8.04737157e-01,\n",
       "         -1.09044300e+00,   1.44747078e+00,  -2.16230682e-01,\n",
       "          2.79506437e+00,   1.31764533e+00,  -4.80530116e+00,\n",
       "         -1.16025232e+01,  -1.48722559e+01,   1.50153359e-01,\n",
       "          9.24217690e+00,  -6.69289668e+00,   2.15478348e+00,\n",
       "         -1.40647020e+01,  -9.58139873e+00,   3.88875217e+00,\n",
       "          7.03731241e+00,   1.65790965e+01,  -2.66740922e-01,\n",
       "          6.45452940e+00,  -2.27467789e+00,   1.82565109e+01,\n",
       "         -5.68015426e+00,   5.76344105e+00,  -6.33961579e+00,\n",
       "         -2.87108799e+00,  -6.78861033e+00,   8.87171978e+00,\n",
       "         -1.37551458e+01,   6.68214808e+00,  -9.08507213e+00,\n",
       "         -1.33603103e+00,   1.72026439e+00,  -7.29327114e+00,\n",
       "         -6.37452347e+00,  -1.55297913e+01,  -1.12693834e+01,\n",
       "          2.23913439e-01,   3.00438159e+00,   1.70912442e+00,\n",
       "         -1.63696670e+01,   8.88243642e+00,   6.83478321e+00,\n",
       "          3.20178518e+00,   1.35005261e+01,  -4.80026262e-02,\n",
       "         -1.31703873e+01,  -3.63921359e-01,  -5.79988649e+00,\n",
       "         -1.62544486e+01,  -1.04437514e+01,  -2.92654396e+00,\n",
       "          1.24252019e+01,   3.35848968e+00,  -5.69178683e+00,\n",
       "          2.30562311e+00,  -4.64794401e+00,  -8.03869914e+00,\n",
       "          6.75109638e+00,  -3.48425832e+00,  -4.05331712e+00,\n",
       "          9.26291104e+00,  -1.19527130e+01,  -3.92805966e+00,\n",
       "          2.32532106e+00,   4.66566716e+00,   7.70595031e+00,\n",
       "         -1.83129129e+01,   1.20044388e+01,   2.69128779e+00,\n",
       "         -1.04643226e+01,  -6.03175466e+00,  -2.91827874e+00,\n",
       "          1.95468469e+01,  -1.61968314e+01,   1.18874622e+01,\n",
       "         -6.39611073e+00,  -1.11700551e+01,  -3.04947920e+00,\n",
       "          8.10372963e+00,   1.68892887e+01,   4.68138398e+00,\n",
       "         -5.46284303e+00,  -4.82594650e+00,  -5.80179947e+00,\n",
       "          5.76994170e+00,  -7.37548690e+00,  -1.10472568e+01,\n",
       "         -8.03743715e+00,   4.54668310e-02,   6.83254516e+00,\n",
       "         -7.73544693e-01,   1.36874072e+01,   1.26523092e+01,\n",
       "         -1.32430174e+01,  -1.23001846e-02,   1.05485735e+01,\n",
       "         -1.43457271e+01,   1.48997189e+01,   1.03476258e+00,\n",
       "         -2.60627308e+00,   3.48546575e+00,  -2.83225658e+00,\n",
       "          6.86324123e+00,   8.52639708e+00,  -1.64335585e+00,\n",
       "         -2.67928332e+00,  -6.22471007e+00,   6.76316826e+00,\n",
       "          3.29864220e+00,   2.20860105e+01,   1.14833844e+01,\n",
       "         -6.23947828e+00,  -4.73107638e-01,  -1.82814488e+00,\n",
       "         -1.39501426e+00,  -1.82957807e+01,  -1.09467456e+01,\n",
       "         -1.13020293e+01,  -1.26860334e+00,   2.36447493e+00,\n",
       "         -1.59796550e+01,  -3.08909214e+00,   2.06431844e+00,\n",
       "          1.86771544e+00,  -8.84969554e+00,   1.36581024e+01,\n",
       "         -4.05982969e+00,   6.18634642e+00,   1.69426833e+01,\n",
       "         -1.05283071e+01,  -6.73975902e+00,  -8.66806555e+00,\n",
       "         -9.20186062e+00,  -1.22575665e+00,  -7.47142585e+00,\n",
       "         -3.49871617e+00,   5.12161347e+00,  -3.86484206e+00,\n",
       "          2.12749567e+01,   3.28550243e+00,   1.22890174e+01,\n",
       "         -1.08027519e+01,   2.63833819e+00,  -5.54071699e+00,\n",
       "         -4.41699821e+00,  -1.23176988e-01,   2.16332976e+00,\n",
       "         -8.97474083e-01,  -2.10091080e+01,  -4.68196074e+00,\n",
       "         -4.30083453e+00,   8.46553129e+00,   1.10988536e+01,\n",
       "          1.15493724e+01,  -4.30244400e-02,  -1.38609818e+00,\n",
       "         -9.96181476e+00,  -7.72592874e+00,   1.29725933e+01,\n",
       "         -7.23688953e-01,  -9.22645776e+00,  -1.44014348e+01,\n",
       "         -5.89401353e+00,  -1.88511267e-01,  -1.09127092e+01,\n",
       "         -2.71110810e+00,   1.79703498e+00,  -7.07946639e-01,\n",
       "         -6.96874337e-01,  -7.09407498e+00,   1.47797573e+01,\n",
       "          1.37820802e+00,   1.19710553e+01,  -8.53139518e+00,\n",
       "          1.69202725e+01,   2.70794653e+00,  -4.68512610e+00,\n",
       "         -1.09164347e+01,   1.19383003e+01,  -7.66715097e+00,\n",
       "          3.61295100e+00,   9.80645777e+00,  -1.02432092e+01,\n",
       "         -1.34195571e+01,   7.42905544e+00,  -1.12470842e+01,\n",
       "          9.21008157e+00,  -1.01466481e+01,   8.93655332e+00,\n",
       "          3.93519553e+00,  -6.78475457e+00,   1.04049573e+01,\n",
       "         -1.34925590e+00,  -1.48568711e+00,   1.04954532e+01,\n",
       "          1.35196061e+01,   9.08140472e+00,   5.74163619e+00,\n",
       "          2.46492570e+00,  -1.60075051e+01,  -9.78470091e-01,\n",
       "         -5.53696687e+00,   6.28945008e+00,   3.29644172e+00,\n",
       "         -4.13428310e+00,  -7.63558659e+00,   5.58062761e-01,\n",
       "         -7.06075657e+00,   3.18148185e-01,  -1.41548123e+01,\n",
       "          9.68340661e-01,  -6.03370972e+00,  -1.48706179e+01,\n",
       "         -4.99684959e+00,   2.60149043e+00,  -2.90264570e+00,\n",
       "         -3.19764900e+00,   5.71851043e+00,  -1.36705412e+01,\n",
       "          3.45921826e+00,   1.62775040e+01,  -1.54342065e+01,\n",
       "          6.61306888e+00,  -5.59532523e-01,  -5.27381923e+00,\n",
       "          1.71088279e+01,   4.05420761e+00,  -9.07618999e+00,\n",
       "          1.31927304e+01,  -1.78895684e+01,  -2.52256554e-01,\n",
       "         -6.19182124e+00,   1.62323973e+01,  -1.44319248e+00,\n",
       "         -1.04142544e+01,   1.03134122e+01,   3.00317834e-01,\n",
       "          6.74060484e-01,  -6.90115457e+00,   1.05130342e+01,\n",
       "         -1.16471352e+01,  -5.89169261e+00,  -2.19866650e+00,\n",
       "          4.23080824e+00,  -6.93105618e+00,  -2.66504853e+00,\n",
       "         -1.14296119e+01,   3.21853240e+00,   9.40281172e+00,\n",
       "         -1.62300731e+01,   6.78945043e+00,  -1.03944358e+01,\n",
       "          1.13006835e+01,  -2.24542404e+00,  -8.57324895e+00,\n",
       "          1.98253372e+01,  -1.40447543e+01,  -7.53126099e+00,\n",
       "         -4.36919815e+00,   5.14293069e+00,   9.92475672e-02,\n",
       "          3.07052721e+00,  -1.24824841e+01,  -1.26767052e+01,\n",
       "          4.37527810e+00,  -3.80749210e+00,   4.99876063e+00,\n",
       "         -1.30381095e+01,   9.70040912e+00,   3.31305687e-01,\n",
       "         -1.33170747e+01,   8.47874170e+00,   1.40998862e+01,\n",
       "          8.34693557e+00,  -1.18259061e+01,  -1.28604304e+01,\n",
       "          2.04222602e+01,  -1.33267588e+01,  -3.33287849e+00,\n",
       "         -5.34512271e+00,   6.69060833e+00,   1.26163869e+00,\n",
       "         -1.16052562e+01,  -7.60482351e-01,  -1.68998922e+01,\n",
       "         -3.86992980e+00,  -5.15238161e+00,  -9.95639944e+00,\n",
       "          7.23049804e+00,   1.36982026e+01,   5.36787235e+00,\n",
       "          1.27850440e+01,   1.31334688e+01,   1.03833942e+01,\n",
       "          2.52752297e+00,  -1.55213089e+01,  -4.82142176e+00]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учитывая, что вероятность принадлежности к классу может принимать значения от 0 до 1, это точно не вероятностные значения. Но мы можем заметить, что все негативные и положительные числа в 'y_pred_raw' сопоставляются с принадлежностью к классу 0 и классу 1, соответственно. Чтобы получить вероятности, нужно обернуть 'y_pred_raw' в сигмоиду, определенную на промежутке [0, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте сигмоиду и постройте её график. Что вы можете сказать об этой функции?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "# sigmoid function\n",
    "def sigmoid(x):\n",
    "    return (1 / (1 + np.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwl1EJA8p3EVE8tD/B0RPzZ/zw4F5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117a93240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10, 10, 1000)\n",
    "\n",
    "plt.title('Sigmoid function')\n",
    "plt.plot(x, sigmoid(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нелинейная гладкая функция. Хорошо дифференциируема -- отлично подходит для реализации градиентного спуска. Область значений функции -- [0, 1] $\\in R$, может быть использована для реализации алгоритмов, выдающих вероятностные значения или классифицирующих. \n",
    "\n",
    "___К тому же (понадобится на 3 курсе):___ может возникнуть проблема \"vanishing gradient\" при обучения нейронной сети с сигмоидой в качестве функции активации, если используем градиентные методы обучения типа Backpropagation. Из-за небольшого порога области значений сигмоиды градиент рискует быть настолько маленьким, что станет неинформативен при обновлении весов --> первые слои нейросети неинформативны --> недообучение или прекращение процесса обучения вообще."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените реализованную сигмоиду к $b(x)$. Вы должны получить вероятности принадлежности к положительному классу. Проверьте, что ваши значения совпали с теми, которые получены с помощью `predict_proba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.42019742e-04,   3.55686727e-07,   3.64087672e-01,\n",
       "          9.98752247e-01,   9.99999996e-01,   9.98892840e-01,\n",
       "          6.48802843e-03,   5.06604516e-02,   9.99863778e-01,\n",
       "          9.23147875e-01,   3.89290032e-01,   1.00008344e-04,\n",
       "          9.88875140e-06,   9.99935696e-01,   9.99464502e-01,\n",
       "          9.91700688e-01,   9.99999775e-01,   2.69117193e-08,\n",
       "          9.99999330e-01,   3.72775339e-05,   5.06695687e-04,\n",
       "          9.20033973e-04,   3.98679160e-01,   9.87638338e-01,\n",
       "          2.77388594e-02,   1.52352491e-05,   6.74035008e-05,\n",
       "          9.99999769e-01,   9.82389681e-01,   9.16688265e-01,\n",
       "          9.16388831e-01,   6.59984835e-01,   9.91834830e-01,\n",
       "          8.67865698e-01,   8.23401872e-01,   9.99999786e-01,\n",
       "          9.99999893e-01,   1.44596488e-07,   1.83758793e-04,\n",
       "          4.15427421e-03,   9.99964967e-01,   7.70756210e-01,\n",
       "          2.96303364e-01,   6.23829934e-03,   9.99903005e-01,\n",
       "          8.65423891e-01,   8.95769785e-02,   5.48957391e-05,\n",
       "          9.99986793e-01,   9.86317259e-07,   7.63348790e-05,\n",
       "          9.99460158e-01,   9.99941492e-01,   9.96682499e-01,\n",
       "          9.99560185e-01,   9.88342748e-01,   1.61750110e-05,\n",
       "          9.28614226e-01,   9.99949723e-01,   9.99970682e-01,\n",
       "          9.99999769e-01,   2.90847324e-01,   3.13613611e-03,\n",
       "          1.18521946e-04,   9.99474280e-01,   2.16450012e-06,\n",
       "          6.50600482e-02,   9.99936974e-01,   9.99963022e-01,\n",
       "          8.85562080e-01,   5.06931776e-04,   9.01265897e-01,\n",
       "          2.42198304e-05,   9.76926160e-01,   9.99885991e-01,\n",
       "          1.68838264e-04,   1.09265953e-03,   7.32640870e-08,\n",
       "          1.68424415e-05,   3.44947044e-01,   2.97751182e-02,\n",
       "          5.12853580e-08,   9.99999966e-01,   9.92452258e-01,\n",
       "          9.97109015e-01,   2.89225933e-06,   9.63812941e-01,\n",
       "          9.97482023e-01,   9.98968282e-01,   6.18904046e-05,\n",
       "          8.42108405e-01,   7.54070971e-02,   7.45704943e-05,\n",
       "          1.16196452e-02,   6.39301734e-04,   2.58200774e-06,\n",
       "          9.99999974e-01,   6.10338320e-02,   9.81040677e-01,\n",
       "          1.13147433e-09,   9.99978445e-01,   2.62375432e-04,\n",
       "          9.99999310e-01,   9.99997242e-01,   1.13424498e-05,\n",
       "          9.65865955e-01,   9.99991971e-01,   6.63850422e-01,\n",
       "          8.98702804e-01,   9.99884901e-01,   3.13772929e-08,\n",
       "          8.59115074e-02,   3.94441449e-07,   6.55943642e-07,\n",
       "          9.99999697e-01,   1.76548534e-04,   9.99626457e-01,\n",
       "          4.35062291e-06,   9.99999079e-01,   4.31356334e-07,\n",
       "          1.32689895e-06,   5.41226042e-01,   9.99313794e-01,\n",
       "          9.99993547e-01,   1.08666258e-03,   9.99999656e-01,\n",
       "          6.84049700e-06,   1.15714593e-02,   9.28742793e-01,\n",
       "          9.99615479e-01,   9.90270906e-01,   3.17134761e-01,\n",
       "          1.43330646e-03,   9.94520784e-01,   9.71829200e-01,\n",
       "          9.99999993e-01,   9.99996770e-01,   9.99865039e-01,\n",
       "          9.99990709e-01,   9.96174080e-01,   9.96262997e-01,\n",
       "          3.61002279e-05,   9.92260185e-01,   4.61907658e-01,\n",
       "          9.99995974e-01,   9.99005498e-01,   9.99572708e-01,\n",
       "          9.99995001e-01,   5.05589561e-07,   9.99603964e-01,\n",
       "          7.48700994e-01,   9.99646326e-01,   9.46275911e-01,\n",
       "          9.64763939e-01,   1.43287824e-04,   1.54308512e-04,\n",
       "          9.99997391e-01,   3.25307021e-04,   2.91835538e-05,\n",
       "          6.47963032e-01,   3.93835249e-05,   9.99999604e-01,\n",
       "          4.27592227e-01,   8.86050476e-01,   1.32697076e-02,\n",
       "          9.98610874e-01,   8.53543103e-03,   2.70239712e-06,\n",
       "          9.69359239e-01,   9.93220523e-01,   2.39403331e-03,\n",
       "          1.13295839e-03,   9.99850606e-01,   5.92394182e-02,\n",
       "          8.50570016e-01,   9.99959133e-01,   3.95395895e-06,\n",
       "          9.96719704e-01,   9.99999854e-01,   9.67623568e-03,\n",
       "          4.52990753e-02,   3.41476165e-01,   3.17564072e-03,\n",
       "          6.37405587e-03,   9.87395312e-01,   8.89300957e-01,\n",
       "          9.99999977e-01,   8.15169885e-01,   1.70101698e-03,\n",
       "          9.99233407e-01,   7.26636650e-02,   4.40506432e-01,\n",
       "          6.41352422e-07,   9.77387766e-01,   9.99998954e-01,\n",
       "          9.99996773e-01,   9.99817172e-01,   9.43780364e-02,\n",
       "          9.99997641e-01,   1.06914345e-01,   9.99825725e-01,\n",
       "          5.97723208e-01,   6.60865286e-01,   9.99998953e-01,\n",
       "          1.28914013e-06,   9.23825853e-03,   9.88390347e-01,\n",
       "          9.99996151e-01,   1.55604573e-03,   9.99833559e-01,\n",
       "          9.99375712e-01,   7.94982790e-01,   4.27379015e-04,\n",
       "          3.23422821e-05,   5.25358290e-01,   6.68755466e-01,\n",
       "          1.36050457e-03,   9.99728038e-01,   9.94769095e-01,\n",
       "          1.25589787e-05,   3.24232583e-03,   9.99993905e-01,\n",
       "          8.74933782e-06,   2.87426358e-06,   9.99995375e-01,\n",
       "          8.77400245e-05,   8.71345312e-06,   3.32769247e-04,\n",
       "          9.99792771e-01,   9.89091921e-01,   8.62306858e-01,\n",
       "          9.99944599e-01,   9.99997528e-01,   9.90789003e-01,\n",
       "          1.33249552e-04,   9.99985010e-01,   9.99499822e-01,\n",
       "          6.99467136e-01,   9.99985081e-01,   9.25737643e-01,\n",
       "          6.56932191e-01,   9.87892208e-01,   9.04359961e-01,\n",
       "          9.99610400e-01,   9.70168333e-01,   3.17390147e-03,\n",
       "          4.97702948e-03,   4.39037462e-03,   9.99753064e-01,\n",
       "          9.98574920e-01,   5.98292537e-03,   9.73541279e-01,\n",
       "          9.66741510e-04,   5.33548005e-04,   8.25095489e-01,\n",
       "          4.89247035e-02,   7.44072549e-01,   2.88029137e-02,\n",
       "          9.90232884e-01,   9.99772867e-01,   5.91874729e-06,\n",
       "          9.98600133e-01,   3.07499960e-04,   4.06028843e-04,\n",
       "          9.94576105e-01,   9.99999948e-01,   4.59657578e-05,\n",
       "          3.32877940e-03,   4.85088400e-01,   9.99999998e-01,\n",
       "          3.53471292e-04,   9.94955408e-01,   9.99629598e-01,\n",
       "          2.91569575e-02,   5.67874783e-07,   9.96409844e-01,\n",
       "          5.32941674e-01,   8.72334244e-01,   3.70064322e-05,\n",
       "          9.96740763e-01,   9.00121642e-01,   1.30860624e-06,\n",
       "          6.85891848e-03,   9.93381238e-01,   7.05981043e-02,\n",
       "          9.99810784e-01,   3.08970543e-07,   9.71272171e-01,\n",
       "          1.53368047e-06,   8.07527549e-01,   2.21249065e-05,\n",
       "          7.45336271e-01,   9.99892157e-01,   5.63284437e-04,\n",
       "          9.06300899e-01,   1.24820620e-04,   9.98243916e-01,\n",
       "          9.99998096e-01,   2.79274319e-03,   9.99999872e-01,\n",
       "          3.51620325e-05,   9.99802016e-01,   3.09013108e-01,\n",
       "          2.51534867e-01,   8.09608880e-01,   4.46151975e-01,\n",
       "          9.42408529e-01,   7.88789684e-01,   8.11976499e-03,\n",
       "          9.14290582e-06,   3.47585136e-07,   5.37467970e-01,\n",
       "          9.99903143e-01,   1.23815167e-03,   8.96114930e-01,\n",
       "          7.79430145e-07,   6.89956068e-05,   9.79939776e-01,\n",
       "          9.99122287e-01,   9.99999937e-01,   4.33707368e-01,\n",
       "          9.98429092e-01,   9.32419534e-02,   9.99999988e-01,\n",
       "          3.40142275e-03,   9.96869543e-01,   1.76187057e-03,\n",
       "          5.36014335e-02,   1.12526555e-03,   9.99859719e-01,\n",
       "          1.06222282e-06,   9.98748485e-01,   1.13332399e-04,\n",
       "          2.08163511e-01,   8.48162888e-01,   6.79637486e-04,\n",
       "          1.70153167e-03,   1.80093177e-07,   1.27574369e-05,\n",
       "          5.55745643e-01,   9.52771680e-01,   8.46722683e-01,\n",
       "          7.77577919e-08,   9.99861214e-01,   9.98925455e-01,\n",
       "          9.60901401e-01,   9.99998630e-01,   4.88001647e-01,\n",
       "          1.90621825e-06,   4.10010648e-01,   3.01875794e-03,\n",
       "          8.72534513e-08,   2.91288765e-05,   5.08568911e-02,\n",
       "          9.99995984e-01,   9.66381744e-01,   3.36221696e-03,\n",
       "          9.09341673e-01,   9.49035101e-03,   3.22624382e-04,\n",
       "          9.98831770e-01,   2.97634631e-02,   1.70682929e-02,\n",
       "          9.99905130e-01,   6.44169137e-06,   1.93019278e-02,\n",
       "          9.10952520e-01,   9.90674811e-01,   9.99550062e-01,\n",
       "          1.11378910e-08,   9.99993883e-01,   9.36510595e-01,\n",
       "          2.85357995e-05,   2.39552455e-03,   5.12573413e-02,\n",
       "          9.99999997e-01,   9.24284011e-08,   9.99993124e-01,\n",
       "          1.66525440e-03,   1.40896623e-05,   4.52399632e-02,\n",
       "          9.99697682e-01,   9.99999954e-01,   9.90818893e-01,\n",
       "          4.22356575e-03,   7.95516817e-03,   3.01300602e-03,\n",
       "          9.96889764e-01,   6.26029458e-04,   1.59305372e-05,\n",
       "          3.23031655e-04,   5.11364750e-01,   9.98923050e-01,\n",
       "          3.15712817e-01,   9.99998863e-01,   9.99996800e-01,\n",
       "          1.77267794e-06,   4.96924993e-01,   9.99973770e-01,\n",
       "          5.88477202e-07,   9.99999662e-01,   7.37838179e-01,\n",
       "          6.87357850e-02,   9.70271385e-01,   5.56057773e-02,\n",
       "          9.98955572e-01,   9.99801872e-01,   1.62008948e-01,\n",
       "          6.42069241e-02,   1.97598552e-03,   9.98845772e-01,\n",
       "          9.64382201e-01,   1.00000000e+00,   9.99989700e-01,\n",
       "          1.94707456e-03,   3.83880972e-01,   1.38459419e-01,\n",
       "          1.98608465e-01,   1.13303513e-08,   1.76149389e-05,\n",
       "          1.23476890e-05,   2.19496430e-01,   9.14077916e-01,\n",
       "          1.14848140e-07,   4.35594427e-02,   8.87386442e-01,\n",
       "          8.66193713e-01,   1.43404829e-04,   9.99998830e-01,\n",
       "          1.69593746e-02,   9.97946894e-01,   9.99999956e-01,\n",
       "          2.67671842e-05,   1.18153451e-03,   1.71961916e-04,\n",
       "          1.00841411e-04,   2.26924974e-01,   5.68792537e-04,\n",
       "          2.93487816e-02,   9.94068998e-01,   2.05356778e-02,\n",
       "          9.99999999e-01,   9.63928096e-01,   9.99995398e-01,\n",
       "          2.03430294e-05,   9.33288573e-01,   3.90837722e-03,\n",
       "          1.19264536e-02,   4.69244630e-01,   8.96907839e-01,\n",
       "          2.89569851e-01,   7.51381205e-10,   9.17586180e-03,\n",
       "          1.33759001e-02,   9.99789440e-01,   9.99984871e-01,\n",
       "          9.99990358e-01,   4.89245549e-01,   2.00031391e-01,\n",
       "          4.71648369e-05,   4.41042253e-04,   9.99997677e-01,\n",
       "          3.26581168e-01,   9.83914986e-05,   5.56590903e-07,\n",
       "          2.74831953e-03,   4.53011252e-01,   1.82247962e-05,\n",
       "          6.23210655e-02,   8.57787622e-01,   3.30052717e-01,\n",
       "          3.32505592e-01,   8.29319856e-04,   9.99999619e-01,\n",
       "          7.98703046e-01,   9.99993675e-01,   1.97140804e-04,\n",
       "          9.99999955e-01,   9.37493925e-01,   9.14712811e-03,\n",
       "          1.81570277e-05,   9.99993465e-01,   4.67730255e-04,\n",
       "          9.73736255e-01,   9.99944908e-01,   3.55971553e-05,\n",
       "          1.48579796e-06,   9.99406604e-01,   1.30451094e-05,\n",
       "          9.99899984e-01,   3.92057423e-05,   9.99868524e-01,\n",
       "          9.80832687e-01,   1.12960777e-03,   9.99969719e-01,\n",
       "          2.05992050e-01,   1.84569951e-01,   9.99972339e-01,\n",
       "          9.99998656e-01,   9.99886251e-01,   9.96800755e-01,\n",
       "          9.21646110e-01,   1.11693739e-07,   2.73195456e-01,\n",
       "          3.92300402e-03,   9.98147657e-01,   9.64306539e-01,\n",
       "          1.57617310e-02,   4.82722103e-04,   6.36004182e-01,\n",
       "          8.57392860e-04,   5.78872884e-01,   7.12266965e-07,\n",
       "          7.24788633e-01,   2.39085691e-03,   3.48154948e-07,\n",
       "          6.71382762e-03,   9.30957440e-01,   5.20229315e-02,\n",
       "          3.92542911e-02,   9.96726153e-01,   1.15600282e-06,\n",
       "          9.69504863e-01,   9.99999915e-01,   1.98156891e-07,\n",
       "          9.98659095e-01,   3.63655632e-01,   5.09788182e-03,\n",
       "          9.99999963e-01,   9.82946640e-01,   1.14343402e-04,\n",
       "          9.99998136e-01,   1.70082307e-08,   4.37268163e-01,\n",
       "          2.04191897e-03,   9.99999911e-01,   1.91051461e-01,\n",
       "          3.00008643e-05,   9.99966816e-01,   5.74520212e-01,\n",
       "          6.62411772e-01,   1.00561027e-03,   9.99972821e-01,\n",
       "          8.74398975e-06,   2.75468799e-03,   9.98703015e-02,\n",
       "          9.85667766e-01,   9.76014929e-04,   6.50675372e-02,\n",
       "          1.08687075e-05,   9.61525759e-01,   9.99917515e-01,\n",
       "          8.94064301e-08,   9.98875678e-01,   3.06013523e-05,\n",
       "          9.99987636e-01,   9.57449089e-02,   1.89061533e-04,\n",
       "          9.99999998e-01,   7.95134068e-07,   5.35774652e-04,\n",
       "          1.25030826e-02,   9.94193366e-01,   5.24791545e-01,\n",
       "          9.55660518e-01,   3.79248946e-06,   3.12302538e-06,\n",
       "          9.87571763e-01,   2.17214945e-02,   9.93298905e-01,\n",
       "          2.17580540e-06,   9.99938745e-01,   5.82077037e-01,\n",
       "          1.64614174e-06,   9.99792203e-01,   9.99999248e-01,\n",
       "          9.99762934e-01,   7.31258750e-06,   2.59887201e-06,\n",
       "          9.99999999e-01,   1.63027729e-06,   3.44603265e-02,\n",
       "          4.74870784e-03,   9.98759015e-01,   7.79308071e-01,\n",
       "          9.11795254e-06,   3.18541552e-01,   4.57583161e-08,\n",
       "          2.04335924e-02,   5.75232853e-03,   4.74209303e-05,\n",
       "          9.99276364e-01,   9.99998876e-01,   9.95357608e-01,\n",
       "          9.99997198e-01,   9.99998022e-01,   9.99969059e-01,\n",
       "          9.26048899e-01,   1.81627294e-07,   7.99095649e-03]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "y_sig = sigmoid(y_pred_raw)\n",
    "y_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.99357980e-01,   6.42019742e-04],\n",
       "       [  9.99999644e-01,   3.55686727e-07],\n",
       "       [  6.35912328e-01,   3.64087672e-01],\n",
       "       ..., \n",
       "       [  7.39511007e-02,   9.26048899e-01],\n",
       "       [  9.99999818e-01,   1.81627294e-07],\n",
       "       [  9.92009044e-01,   7.99095649e-03]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`y_pred_1` выдает вероятности принадлежности к классам 0 и 1 для каждого объекта, тогда как `sigmoid(y_pred_raw)` выдает только вероятности принадлежности к классу 1. Посмотрим только на второй столбец значений `y_pred_1` -- они идентичны выдаче `sigmoid(y_pred_raw)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, обучение логистической регрессии — настройка параметров $w$ и $w_0$, а применение — подсчёт вероятностей принадлежности положительному классу как применение сигмоды к скалярному произведению признаков и параметров.\n",
    "\n",
    "Постройте для обученной логистической регрессии ROC-кривую `roc_curve` и PR-кривую `precision_recall_curve`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fpr, tpr, thresholds\n",
    "x, y, t = roc_curve(y_test, y_sig.reshape([600, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1Ca1//keAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115638518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мечта датасаентолога, почти roc-haven (0,1)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# precision, recall, thresholds\n",
    "y, x, t = precision_recall_curve(y_test, y_sig.reshape([600, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b8e29e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y)\n",
    "plt.ylabel(\"precision\")\n",
    "plt.xlabel(\"recall\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Практически идеальное соотношение точности и полноты предсказаний (1, 1). Почти всегда можем доверять классификатору при предсказании положительного класса (точность), доля найденных положительных ответов крайне высока (полнота)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Итог:__ Наш классификатор всех прекраснее на свете!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бонусное задание. Обучение логистической регрессии.\n",
    "\n",
    "[2 бонусных балла]\n",
    "\n",
    "Если выше вручную мы только применяли логистическую регрессию, то здесь предлагается реализовать обучение с помощью полного градиентного спуска.\n",
    "\n",
    "Если кратко, то обучение логистической регрессии с $L_2$-регуляризацией можно записать следующим образом:\n",
    "\n",
    "$$\n",
    "Q(w, X) = \\frac{1}{l} \\sum_{i=1}^{l} \\log (1 + \\exp(- y_i \\langle w, x_i \\rangle )) + \\frac{\\lambda_2}{2} \\lVert w \\rVert _2^2 \\to \\min_w\n",
    "$$\n",
    "\n",
    "Считаем, что $y_i \\in \\{-1, +1\\}$, а нулевым признаком сделан единичный (то есть $w_0$ соответствует свободному члену). Искать $w$ будем с помощью градиентного спуска:\n",
    "\n",
    "$$\n",
    "w^{(k+1)} = w^{(k)} - \\alpha \\nabla_w Q(w, X)\n",
    "$$\n",
    "\n",
    "В случае полного градиентного спуска $\\nabla_w Q(w, X)$ считается напрямую (как есть, то есть, используя все объекты выборки). Длину шага $\\alpha > 0$ в рамках данного задания предлагается брать равной некоторой малой константе.\n",
    "\n",
    "Градиент по объекту $x_i$ считается по следующей формуле:\n",
    "\n",
    "$$\n",
    "\\nabla_w Q(w, x_i) = - \\frac{y_i x_i}{1 + \\exp(y_i \\langle w, x_i \\rangle)} + \\lambda_2 w\n",
    "$$\n",
    "\n",
    "На самом деле неправильно регуляризировать свободный член $w_0$ (то есть при добавлении градиента для $w_0$ не надо учитывать слагаемое с $\\lambda_2$). Но в рамках этого задания мы не обращаем на это внимания и работаем со всеми вектором весов одинаково. \n",
    "\n",
    "В качестве критерия останова необходимо использовать (одновременно):\n",
    "- проверку на евклидовую норму разности весов на двух соседних итерациях (например, меньше некоторого малого числа порядка $10^{-6}$) — параметр tolerance\n",
    "- достижение максимального числа итераций (например, 10000) — параметр max\\_iter.\n",
    "\n",
    "Инициализировать веса можно случайным образом или нулевым вектором.\n",
    "\n",
    "Реализуйте обучение логистической регрессии. Для удобства ниже предоставлен прототип с необходимыми методами. В `loss_history` необходимо сохранять вычисленное на каждой итерации значение функции потерь. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class LogReg(BaseEstimator):\n",
    "    def __init__(self, lambda_2 = 1.0, tolerance = 1e-4, max_iter = 1000, alpha = 1e-3):\n",
    "        \"\"\"\n",
    "        lambda_2: L2 regularization param\n",
    "        tolerance: for stopping gradient descent\n",
    "        max_iter: maximum number of steps in gradient descent\n",
    "        alpha: learning rate\n",
    "        \"\"\"\n",
    "        self.lambda_2 = lambda_2\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iter = max_iter\n",
    "        self.alpha = alpha\n",
    "        self.w = None\n",
    "        self.loss_history = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d)\n",
    "        y: np.array of shape (l)\n",
    "        ---\n",
    "        output: self\n",
    "        \"\"\"\n",
    "        self.loss_history = []\n",
    "        \n",
    "        y = np.array(y)\n",
    "        y[y == 0] = -1 # replace y to discrete values [-1; 1]\n",
    "        X = np.concatenate([np.ones(X.shape[0]).reshape([-1, 1]), X], axis = 1) # add ones as intercepts\n",
    "        X = preprocessing.scale(X) # standartization\n",
    "        \n",
    "        # initialize some very normal weights\n",
    "        self.w = np.random.normal(size = (X.shape[1], 1), scale = .01)\n",
    "        # or define zero weights \n",
    "        # self.w = np.zeros(X.shape[1])\n",
    "        \n",
    "        # loop\n",
    "        meme = 0\n",
    "        while meme <= self.max_iter:\n",
    "            meme += 1\n",
    "            old_weights = self.w\n",
    "            self.loss_history.append(self.calc_loss(X, y)) # append loss for old weights to history\n",
    "            self.w = (self.w.T - self.alpha * self.calc_gradient(X, y)).T # update weights\n",
    "            print(meme)\n",
    "            print(self.loss_history[-1])\n",
    "            if (self.loss_history[-1] - self.calc_loss(X, y) < self.tolerance): # old - new\n",
    "                self.w = old_weights\n",
    "                break\n",
    "                \n",
    "\n",
    "        #print(meme)\n",
    "        #print(self.w)\n",
    "        #print(old_weights)\n",
    "        #print(X)\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d)\n",
    "        ---\n",
    "        output: np.array of shape (l, 2) where\n",
    "        first column has probabilities of -1\n",
    "        second column has probabilities of +1\n",
    "        \"\"\"\n",
    "        if self.w is None:\n",
    "            raise Exception('Not trained yet')\n",
    "\n",
    "        best_scores = X.dot(self.w) # scores shape (l, 1)\n",
    "        prob_plus = np.array(1 / (1 + np.exp(-best_scores))) # sigmoid to get propabilities [0,1]\n",
    "        \n",
    "        return np.concatenate([1 - prob_plus, prob_plus], axis = 1)\n",
    "    \n",
    "    def calc_gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d) (l can be equal to 1 if stochastic)\n",
    "        y: np.array of shape (l)\n",
    "        ---\n",
    "        output: np.array of shape (d)\n",
    "        \"\"\"\n",
    "        # MINUS BEFORE GRADIENT\n",
    "        # add minus before exp?\n",
    "        gradient = -y.dot(X) / (1 + np.exp(y.dot((self.w * X.T).T))) + self.lambda_2 * self.w.T\n",
    "        return gradient\n",
    "\n",
    "        \n",
    "    def calc_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d)\n",
    "        y: np.array of shape (l)\n",
    "        ---\n",
    "        output: float \n",
    "        \"\"\" \n",
    "        # w*X shape (l, 1)\n",
    "        # shape of weights (d, 1)\n",
    "        reg = self.lambda_2/2 * np.sum(abs(self.w)**2)\n",
    "        \n",
    "        loss = 1/len(y) * np.sum(np.log(1 + np.exp(-y*(X.dot(self.w))))) + reg\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_lr = LogReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "970.848791429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogReg(alpha=0.001, lambda_2=1.0, max_iter=1000, tolerance=0.0001)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Итог:__\n",
    "\n",
    "У меня не вышло, но я пыталась :(\n",
    "\n",
    "Там какая-то проблема с подсчетом градиента, как мне кажется. Разбивала код и прогоняла в отдельных ячейках, так и не смогла найти проблему. В каких-то случаях лосс становился крошечным, но я уже не помню, где так было, надо снова членить код.\n",
    "\n",
    "Еще кажется, после поисков в интернетах, что экспоненту внутри градиента нужно возводить в отрицательную степень. Но это не помогает..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Примените логистическую регресиию на той же выборке.\n",
    "2. Посчитайте качество по тем же метрикам.\n",
    "3. Визуализируйте изменение значений функции потерь от номера итераций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Случайные леса.\n",
    "\n",
    "[6 баллов]\n",
    "\n",
    "Случайный лес — алгоритм машинного обучения, представляющий собой бэггинг над решающими деревьями (усреднение ответов множества слабых алгоритмов) с 2 основными идеями:\n",
    "- Использование подмножества признаков при построении каждого сплита дерева.\n",
    "- Бутстрап обучающей выборки для построения каждого дерева (с повторениями).\n",
    "\n",
    "В этом задании мы попробуем оценить пользу каждой из идей. Будем использовать ту же выборку с тем же разбиением на 2 части. Для начала обучите решающее дерево `DecisionTreeClassifier` из scikit-learn и посчитайте ROC-AUC и Accuracy (порог 0.5). Не забудьте зафикиксировать сид для построения дерева (несмотря на то, что в классической реализации никакой случайности нет, при большой глубине дерева может возникать неоднозначность в выборке признака в сплите). Используйте этот сид для всех заданий ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_grid = GridSearchCV(estimator=tree, param_grid = {'criterion': ['gini', 'entropy']})\n",
    "tree_grid.fit(X_train, y_train)\n",
    "\n",
    "tree_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 123)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tree = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94845337849884115"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roc-auc\n",
    "roc_auc_score(y_test, y_pred_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94833333333333336"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "accuracy_score(y_test, y_pred_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики для дерева чуть хуже, чем для логита."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Бэггинг классификаторов\n",
    "\n",
    "Реализуйте бэггинг над решающими деревьями (усреднение предсказанных вероятностей всего ансамбля). \n",
    "В качестве основы используйте всё тот же `DecisionTreeClassifier`. Количество базовых алгоритмов предлагается брать равным 100. \n",
    "\n",
    "Посчитайте качество с помощью тех же метрик. Ответьте на следующие вопросы:\n",
    "- Что интересного вы видите?\n",
    "- С чем это связано?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag = BaggingClassifier(base_estimator = tree, bootstrap = False, n_estimators = 100, random_state = 123)\n",
    "\n",
    "bag.fit(X_train, y_train)\n",
    "y_pred_bag = bag.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94827509359957207"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roc-auc\n",
    "roc_auc_score(y_test, y_pred_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94833333333333336"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "accuracy_score(y_test, y_pred_bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики особо не изменились, на очень малое число уменьшился roc-auc. Скорее всего это связано с тем, что здесь мы осуществляем беггинг над параметрами, не рандомизируя сами деревья. В таком случае агрегиррованные предикторы, полученые с помощью беггинга, могут действительно понижать разброс предсказаний от разных алгоритмов (=деревьев с разными параметрами), повышая точность предсказаний (accuracy не изменилась по сранению с обычным решающим деревом, обученным выше). \n",
    "\n",
    "Но поскольку сам процесс выбора итогового алгоритма не случайный и зависит только от показателей качества деревьев на training data, есть шанс переобучения -- после нерандомизированного беггинга roc-auc немного понизился. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Сэмплирование обучающей выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим к нашему бэггингу бутстрап выборки (генерация случайной выборки того же размера с возвращением). Для этого может пригодиться `numpy.random.randint`.\n",
    "\n",
    "Посчитайте качество. Что вы видите?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)  # для одинакового бутстрапа в каждом запуске\n",
    "\n",
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "rand_bag = BaggingClassifier(base_estimator = tree, bootstrap = True, n_estimators = 100, random_state = 123)\n",
    "\n",
    "rand_bag.fit(X_train, y_train)\n",
    "y_pred_rand_bag = rand_bag.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96305045462649319"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roc-auc\n",
    "roc_auc_score(y_test, y_pred_rand_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96333333333333337"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "accuracy_score(y_test, y_pred_rand_bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Обе метрики сильно улучшились и по сравнению с обычным решающим деревом, и по сравнению с нерандомизированным беггингом. Бутстрап обладает замечательным свойством -- борьбой с переобучением, что и помогло получить более робастные, качественные оценки при проверке качества алгоритма на тестовой выборке. \n",
    "\n",
    "Семплируя выборки, на которых происходит обучение деревьев, мы с большей вероятностью получаем выборки с разными распределениями. В таком случае у алгоритма нет возможности \"подстроиться\" под данные, и он будет устойчив на тренировочном сете. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Выбор случайного подмножества признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Временно забудем о бутстрапе выборки и добавим выбор случайного подмножества признаков при построении каждого сплита. В `DecisionTreeClassifier` за это отвечает параметр `max_features`. По умолчанию он имеет значение `None`, что обозначает использование всех возможных признаков. Для задачи классификации рекоменуется использовать квадратный корень от количества признаков. Попробуйте выставить такое значение. На этот раз надо отключить фиксированный сид в построении дерева, так как иначе каждый раз мы будем выбирать одинаковые подмножества признаков. \n",
    "\n",
    "Посчитайте качество. Что вы видите?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)  # для воспроизводимости построения случайных подмножеств признаков\n",
    "\n",
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "tree = DecisionTreeClassifier(criterion = 'entropy', max_features = int(round(sqrt(X_train.shape[1]))))\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tree2 = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88846050989481196"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88833333333333331"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_tree2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество сильно ухудшилось по сравнению с обычным решающим деревом, нерандомизированным и рандомизированным беггингом. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 = 2.2 + 2.3\n",
    "\n",
    "Объединим два подхода (бутстрап + выбор подмножества признаков). Получим случайный лес.\n",
    "\n",
    "Посчитайте качество. Что вы видите?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)  # для одинакового бутстрапа и выбора подмножеств признаков в каждом запуске\n",
    "\n",
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_features = int(round(sqrt(X_train.shape[1]))))\n",
    "tree24 = BaggingClassifier(base_estimator = tree, bootstrap = True, n_estimators = 100, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree24.fit(X_train, y_train)\n",
    "y_pred24 = tree24.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96305045462649319"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96333333333333337"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики вернулись к состоянию, в котором пребывали на пункте беггинга с бутстрапом. Вывод -- случайное подмножество признаков является недостаточным \"уровнем\" рандомизации. Беггинг и бутстрап наше все. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То, что мы сделали уже реализовано в `RandomForestClassifier`. Попробуйте воспользоваться им. Количество используемых деревьев передаётся в параметре `n_estimators`.\n",
    "\n",
    "Посчитайте качество. Что вы видите?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97149670172936342"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97166666666666668"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики значительно улучшились и чуть выше тех, которые мы получили на шаге 2.4. Видимо, это связано с тем, что `RandomForestClassifier` по дефолту использует более оптимальные гиперпараметры для обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Влияние количества используемых деревьев в случайном лесе\n",
    "\n",
    "Один из параметров случайного леса — количество деревьев, используемых в бэггинге. Оценим, как влияет этот параметр на финальное качество. Для этого обучите случайные леса с разным количество деревьев (например, перебирайте от 10 до 1000 с шагом в 10), оцените качество с помощью ROC-AUC. Постройте график зависимости ROC-AUC от количества используемых деревьев. Что вы видите?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "rf = RandomForestClassifier(criterion='entropy')\n",
    "# gridsearch CV for hyperpar\n",
    "rf_grid = GridSearchCV(estimator=rf, scoring='roc_auc', param_grid = {'n_estimators': np.arange(10, 1010, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 980}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting quality metrics from GridSearch\n",
    "# creating a dictionary with roc-auc values as values\n",
    "# and RandomForestClassifier's hyperparameters as keys\n",
    "\n",
    "results = {}\n",
    "for i in range(0, len(rf_grid.grid_scores_)):\n",
    "    results[rf_grid.grid_scores_[i][0]['n_estimators']] = rf_grid.grid_scores_[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators\n",
    "x = list(results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC values\n",
    "y = list(results.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niCYJJBER0SSBJCIimnwH++fNIrTDFUAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11064b048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('ROC-AUC values depending on the number of trees')\n",
    "plt.plot(x, y)\n",
    "xlabel('# trees')\n",
    "ylabel('ROC-AUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC-AUC приближается к heaven после количества деревьев, используемых в беггинге, $\\approx 80$. Как показал `GridSearch`, 980 деревьев для беггинга дают наилуший результат. Большее количество деревьев в \"лесу\" дает возможность хорошей рандомизации и предотвращает переобучение. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy', n_estimators=980)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_best = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97149670172936342"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97166666666666668"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достигли рая. В целом наши метрики не отличаются от тех, которые мы получили с `RandomForestClassifier` без указания гиперпараметра с количеством деревьев для беггинга. Видимо, это связано с тем, что в целом Random Forest, благодаря разным способам рандомизации и усреднению ответов, благодаря работе с разнообразными деревьями, находит оптимальные гиперпараметры ансамбля. \n",
    "\n",
    "Random Forest ищет лучшие параметры среди всех рандомно выбранных выборок параметров деревьев, и у него получается хорошо предсказывать!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Важность признаков\n",
    "\n",
    "Случайный лес позволяет оценить важность признаков. У обученного случайного леса есть аттрибут `feature_importances_`, где храниться важность для каждого признака. Постройте `barplot` с важностью признаков (удобно использовать библиотеку `seaborn`, где можно для каждого столбца передать название признака `train.columns`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "importances = rf.feature_importances_\n",
    "features = X_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x110a62f28>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhMAAAFJCAYAAAAhXq8oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110a62f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(y = features, x = importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, самый важный признак -- Random Access Memory in Megabytes. Второй по важности -- battery power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "Напишите, что интересного вы узнали в этой работе, в каких экспериментах какие результаты получились.\n",
    "\n",
    "1) __По логиту__:\n",
    "- Логит используется в случае, если отклик имеет бинарную или категориальную природу.\n",
    "- Может быть использован как для регрессии, так и для классификации. \n",
    "- Логистическая функция (=сигмоида) имеет S-образную shape, определенную на отрезке [0, 1], что позволяет не только разделять данные на классы, но и описывать присвоение к классу в вероятностных значениях. Коэффициенты подбираются так же, как и в линейных регрессиях, -- с помощью MLE. Оболочка сигмоиды обязательна, если мы хотим получить в итоге предсказания (принадлежности к классу в задаче на классификацию). \n",
    "- Для логита можем вполне использовать регуляризацию, чтобы бороться с переобучнием и повышать качество алгоритма. \n",
    "- Поскольку сигмоида -- гладкая функция, с ней хорошо работают алгоритмы обучения, основанные на градиентном спуске. Но (при обучении нейроннных сеток с back propogation) может возникнуть проблема исчезающего градиента, когда значения градиенты настолько малы, что веса не обновляются, процесс обучения не происходит. \n",
    "- Минус: сложно писать класс, реализующий логит с полным градиентном спуском и не запутаться :)\n",
    "\n",
    "2) __По Random Forest__:\n",
    "- Важные преимущества случайного леса: 1) работа с категориальными переменными, 2) обучение как классификатора, так и регрессии. \n",
    "- Random Forest случайно генерит количество наблюдений и параметры, на которых обучаются решающие деревья. Затем усредняет их ответы. Это помогает эффективно бороться с переобучением и получать отлиные показатели качества. Random Forest большой молодец!\n",
    "- Проблема случайного леса: если `n_estimators` слишком большое, лес долго обучается (технически затратен).\n",
    "- Гораздо мощнее по сравнению с обычным решающим деревом. Даже без поиска оптимального гиперпараметра с GridSearch, с дефолтными гиперпараметрами случайного леса можно получить очень точные предсказания и высокие показатели качество алгоритма случайного леса. \n",
    "\n",
    "И с помощью логита, и с помощью случайного леса мы итого достигли примерно одинакового качества алгоритмов: 0.97 и для accuracy, и для roc-auc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
